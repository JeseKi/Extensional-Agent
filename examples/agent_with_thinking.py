"""
å¸¦æ€è€ƒçš„Agentå®ç°

æœ¬æ–‡ä»¶å®ç°äº†ä¸€ä¸ªæ”¯æŒæ¨ç†æ€è€ƒçš„Agentï¼Œæ ¸å¿ƒåŠŸèƒ½æ˜¯ä»Qwen3-32Bæ¨¡å‹çš„å“åº”ä¸­
è§£æreasoning_contentå­—æ®µå¹¶é€šè¿‡extensional_agentæ¡†æ¶è¿›è¡Œä¼ è¾“ã€‚

å…¬å¼€æ¥å£:
- ThinkingDemoAgent: å¸¦æ€è€ƒçš„æ¼”ç¤ºAgentç±»

å†…éƒ¨æ–¹æ³•:
- run(): ä¸»è¦çš„Agentæ‰§è¡Œæ–¹æ³•
- _execute_tool_call(): å·¥å…·è°ƒç”¨æ‰§è¡Œæ–¹æ³•

å·¥å…·å‡½æ•°:
- get_weather(): æ¨¡æ‹Ÿå¤©æ°”æŸ¥è¯¢
- get_temperature(): æ¨¡æ‹Ÿæ¸©åº¦æŸ¥è¯¢

æ•°æ®æ¨¡å‹:
Agentå¤„ç†çš„æ ¸å¿ƒæ˜¯å°†LLMçš„reasoning_contentå­—æ®µæå–å¹¶å°è£…åˆ°ExecutionRecordä¸­ï¼Œ
é€šè¿‡emit_eventå‘é€ç»™è®¢é˜…è€…ã€‚

å®ç°é‡ç‚¹:
è¿™æ˜¯ä¸€ä¸ªçº¯ç²¹çš„Agentå®ç°ï¼Œåªè´Ÿè´£LLMè¾“å‡ºè§£æå’Œreasoning_contentæå–ã€‚
"""

import asyncio
import os
import json
import random
from typing import Dict, Any
from uuid import UUID, uuid4

import openai
from dotenv import load_dotenv

from extensional_agent import ITanWeAIAgent, emit_event, ExecutionRecord, Role, ToolCall

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()


# æ¼”ç¤ºå·¥å…·å‡½æ•°
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”æƒ…å†µï¼ˆæ¨¡æ‹Ÿï¼‰"""
    weather_conditions = ["æ™´å¤©", "å¤šäº‘", "å°é›¨", "ä¸­é›¨", "é˜´å¤©", "é›·é˜µé›¨"]
    return random.choice(weather_conditions)


def get_temperature(city: str) -> int:
    """è·å–æŒ‡å®šåŸå¸‚çš„æ¸©åº¦ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return random.randint(-10, 40)  # æ¨¡æ‹Ÿæ¸©åº¦èŒƒå›´ -10Â°C åˆ° 40Â°C


class ThinkingDemoAgent(ITanWeAIAgent):
    """
    å¸¦æ€è€ƒçš„æ¼”ç¤ºAgent
    
    è¯¥Agentç”¨äºæ¼”ç¤ºï¼š
    1. å¦‚ä½•è§£æå’Œå±•ç¤ºreasoning_contentå­—æ®µ
    2. å·¥å…·è°ƒç”¨çš„å®Œæ•´æµç¨‹ï¼ˆå¤©æ°”ã€æ¸©åº¦æŸ¥è¯¢ï¼‰
    3. æµå¼äº‹ä»¶å¤„ç†å’Œæ€è€ƒå†…å®¹ä¼ è¾“
    4. å®æ—¶æ¨ç†è¿‡ç¨‹ç›‘æ§
    """
    AGENT_NAME = "thinking_demo_agent"

    def __init__(self):
        """åˆå§‹åŒ–Agentï¼Œé…ç½®OpenAIå®¢æˆ·ç«¯"""
        # ä»ç¯å¢ƒå˜é‡è·å– OpenAI API é…ç½®
        base_url = os.getenv("OPENAI_BASE_URL")
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not base_url or not api_key:
            raise ValueError("è¯·ç¡®ä¿è®¾ç½®äº†OPENAI_BASE_URLå’ŒOPENAI_API_KEYç¯å¢ƒå˜é‡")
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.openai_client = openai.AsyncOpenAI(
            base_url=base_url,
            api_key=api_key
        )

    async def run(self, agent_input: str) -> str:
        """
        è¿è¡Œå¸¦æ€è€ƒçš„æ¼”ç¤ºAgent
        
        Args:
            agent_input: Agent çš„è¾“å…¥
            
        Returns:
            æœ€ç»ˆçš„è¾“å‡º
            
        æ•°æ®æµ:
        1. æ„å»ºåŒ…å«å·¥å…·å®šä¹‰çš„æç¤ºè¯
        2. è°ƒç”¨Qwen3-32Bæ¨¡å‹è·å–æµå¼å“åº”
        3. è§£æreasoning_contentå­—æ®µè·å–æ€è€ƒè¿‡ç¨‹
        4. å¤„ç†å·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœ
        5. é€šè¿‡emit_eventå‘é€äº‹ä»¶ç»™è®¢é˜…è€…
        """
        print("ğŸ” [è°ƒè¯•] ThinkingDemoAgent.run() è¢«è°ƒç”¨")
        print(f"ğŸ” [è°ƒè¯•] agent_input: {agent_input}")
        print(f"ğŸ” [è°ƒè¯•] OpenAI client é…ç½® - base_url: {self.openai_client.base_url}")
        print(f"ğŸ” [è°ƒè¯•] OpenAI client é…ç½® - api_key: {self.openai_client.api_key[:10]}...")
        # æ„å»ºç”¨äºæ¼”ç¤ºå·¥å…·è°ƒç”¨å’Œæ€è€ƒçš„æç¤ºè¯
        messages = [
            {
                "role": "system", 
                "content": """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢å¤©æ°”å’Œæ¸©åº¦ä¿¡æ¯ã€‚

åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œè¯·è¯¦ç»†å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. å¯¹ç”¨æˆ·é—®é¢˜çš„ç†è§£
2. éœ€è¦è°ƒç”¨å“ªäº›å·¥å…·æ¥è·å–ä¿¡æ¯
3. å¦‚ä½•å¤„ç†å’Œåˆ†æè·å–åˆ°çš„æ•°æ®
4. æœ€ç»ˆå¦‚ä½•ç»„ç»‡ç­”æ¡ˆ

è¯·å…ˆæ€è€ƒï¼Œç„¶åæ ¹æ®éœ€è¦è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚"""
            },
            {
                "role": "user", 
                "content": f"è¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ {agent_input} è¿™ä¸ªåœ°æ–¹çš„å¤©æ°”æƒ…å†µå’Œæ¸©åº¦ã€‚è¯·è¯¦ç»†è¯´æ˜ä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚"
            }
        ]
        
        # å®šä¹‰å¯ç”¨çš„å·¥å…·
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”æƒ…å†µ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°"
                            }
                        },
                        "required": ["city"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_temperature",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„æ¸©åº¦",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°"
                            }
                        },
                        "required": ["city"]
                    }
                }
            }
        ]
        
        # ä¸ºè¿™æ¬¡æµå¼å“åº”ç”Ÿæˆå”¯ä¸€çš„ stream_id
        stream_id = uuid4()
        chunk_index = 0
        
        # ç”¨äºç§¯ç´¯æµå¼å·¥å…·è°ƒç”¨çš„æ•°æ®ç»“æ„
        tool_calls_buffer = {}  # tool_call_index -> {id, name, arguments}

        try:
            print("ğŸ” [è°ƒè¯•] å¼€å§‹è°ƒç”¨ OpenAI API...")
            print("ğŸ” [è°ƒè¯•] ä½¿ç”¨æ¨¡å‹: Qwen3-32B")
            print(f"ğŸ” [è°ƒè¯•] æ¶ˆæ¯å†…å®¹: {messages[-1]['content']}")
            
            # è°ƒç”¨ Qwen3-32B æ¨¡å‹è·å–æµå¼å“åº”
            stream = await self.openai_client.chat.completions.create(
                model="Qwen3-32B",  # ä½¿ç”¨æŒ‡å®šçš„Qwen3-32Bæ¨¡å‹
                messages=messages, # type: ignore
                tools=tools,  # æä¾›å·¥å…·å®šä¹‰ # type: ignore
                stream=True,
                temperature=0.7,  # é€‚åº¦çš„åˆ›é€ æ€§ï¼Œä¿æŒæ¨ç†çš„å¤šæ ·æ€§
                max_tokens=2000   # ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´è¿›è¡Œè¯¦ç»†æ¨ç†
            )
            
            print("ğŸ” [è°ƒè¯•] OpenAI API è°ƒç”¨æˆåŠŸï¼Œå¼€å§‹å¤„ç†æµå¼å“åº”...")
            chunk_count = 0
            
            async for chunk in stream:
                chunk_count += 1
                print(f"ğŸ” [è°ƒè¯•] æ”¶åˆ°ç¬¬ {chunk_count} ä¸ª chunk")
                
                choice = chunk.choices[0]
                delta = choice.delta
                is_stop = choice.finish_reason is not None
                
                print(f"ğŸ” [è°ƒè¯•] chunk è¯¦æƒ…: is_stop={is_stop}, finish_reason={choice.finish_reason}")
                if hasattr(delta, 'content') and delta.content:
                    print(f"ğŸ” [è°ƒè¯•] delta.content: {delta.content}")
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                    print(f"ğŸ” [è°ƒè¯•] delta.reasoning_content: {delta.reasoning_content}")
                if hasattr(delta, 'tool_calls') and delta.tool_calls:
                    print(f"ğŸ” [è°ƒè¯•] delta.tool_calls: {delta.tool_calls}")

                # å¤„ç†æ¨ç†æ€è€ƒå†…å®¹ - ä»reasoning_contentå­—æ®µæå–
                reasoning_content = None
                if hasattr(choice, 'message') and hasattr(choice.message, 'reasoning_content'):
                    reasoning_content = choice.message.reasoning_content
                elif hasattr(delta, 'reasoning_content'):
                    reasoning_content = delta.reasoning_content
                
                # å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œä¼˜å…ˆå‘é€æ€è€ƒè¿‡ç¨‹
                if reasoning_content:
                    thinking_record = ExecutionRecord(
                        id=stream_id,
                        index=chunk_index,
                        role=Role.ASSISTANT,
                        reasoning_content=reasoning_content,  # è®¾ç½®æ€è€ƒå†…å®¹
                        content=None,  # æ€è€ƒé˜¶æ®µä¸è®¾ç½®å¸¸è§„å†…å®¹
                        tool_call=None,
                        is_stop=False  # æ€è€ƒé˜¶æ®µä¸æ˜¯ç»“æŸ
                    )
                    await emit_event(execution_record=thinking_record)
                    chunk_index += 1

                # å¤„ç†æµå¼æ–‡æœ¬å†…å®¹ - æœ€ç»ˆç­”æ¡ˆ
                if delta.content:
                    content_record = ExecutionRecord(
                        id=stream_id,
                        index=chunk_index,
                        role=Role.ASSISTANT,
                        reasoning_content=None,  # å†…å®¹é˜¶æ®µä¸é‡å¤æ€è€ƒå†…å®¹
                        content=delta.content,
                        tool_call=None,
                        is_stop=is_stop
                    )
                    await emit_event(execution_record=content_record)
                    chunk_index += 1

                # å¤„ç†å·¥å…·è°ƒç”¨ - æµå¼ç§¯ç´¯æ¨¡å¼
                if delta.tool_calls:
                    for tool_call in delta.tool_calls:
                        # ä½¿ç”¨ index ä½œä¸ºå·¥å…·è°ƒç”¨çš„æ ‡è¯†ï¼Œå› ä¸º id åœ¨åç»­ chunk ä¸­å¯èƒ½ä¸º None
                        tool_call_index = tool_call.index
                        tool_call_id = tool_call.id
                        
                        print(f"ğŸ” [è°ƒè¯•] å¤„ç†å·¥å…·è°ƒç”¨ index={tool_call_index}, id={tool_call_id}: name={tool_call.function.name}, args='{tool_call.function.arguments}'")
                        
                        # åˆå§‹åŒ–æˆ–æ›´æ–°å·¥å…·è°ƒç”¨ç¼“å†²åŒº
                        if tool_call_index not in tool_calls_buffer:
                            tool_calls_buffer[tool_call_index] = {
                                'id': tool_call_id,  # ä¿å­˜ç¬¬ä¸€æ¬¡å‡ºç°æ—¶çš„ ID
                                'name': '',
                                'arguments': ''
                            }
                        
                        # ç§¯ç´¯å·¥å…·åç§°ï¼ˆé€šå¸¸åœ¨ç¬¬ä¸€ä¸ªchunkä¸­å®Œæ•´ä¼ è¾“ï¼‰
                        if tool_call.function.name:
                            tool_calls_buffer[tool_call_index]['name'] = tool_call.function.name
                        
                        # ç§¯ç´¯å·¥å…·å‚æ•°ï¼ˆå¯èƒ½åˆ†å¤šä¸ªchunkä¼ è¾“ï¼‰
                        if tool_call.function.arguments:
                            tool_calls_buffer[tool_call_index]['arguments'] += tool_call.function.arguments
                        
                        print(f"ğŸ” [è°ƒè¯•] å½“å‰ç§¯ç´¯çŠ¶æ€ index={tool_call_index}: {tool_calls_buffer[tool_call_index]}")
                        
                        # å°è¯•æ£€æŸ¥æ˜¯å¦ä¸ºå®Œæ•´çš„JSONï¼ˆç®€å•æ£€æŸ¥ï¼šå¼€å§‹å’Œç»“æŸæ‹¬å·åŒ¹é…ï¼‰
                        current_args = tool_calls_buffer[tool_call_index]['arguments']
                        if current_args and current_args.strip().startswith('{') and current_args.strip().endswith('}'):
                            # å°è¯•è§£æå®Œæ•´çš„å·¥å…·è°ƒç”¨
                            try:
                                args_dict = json.loads(current_args)
                                tool_name = tool_calls_buffer[tool_call_index]['name']
                                
                                if tool_name:  # ç¡®ä¿å·¥å…·åç§°ä¹Ÿå·²å®Œæ•´æ¥æ”¶
                                    print(f"ğŸ” [è°ƒè¯•] å·¥å…·è°ƒç”¨å®Œæ•´ï¼Œå‡†å¤‡æ‰§è¡Œ: {tool_name}({args_dict})")
                                    
                                    # å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
                                    tool_record = ExecutionRecord(
                                        id=stream_id,
                                        index=chunk_index,
                                        role=Role.ASSISTANT,
                                        tool_call=ToolCall(
                                            name=tool_name,
                                            args=args_dict
                                        ),
                                        is_stop=False
                                    )
                                    await emit_event(execution_record=tool_record)
                                    chunk_index += 1
                                    
                                    # æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶å‘é€ç»“æœ
                                    await self._execute_tool_call(
                                        stream_id, chunk_index, tool_name, args_dict
                                    )
                                    chunk_index += 1
                                    
                                    # æ¸…é™¤å·²å¤„ç†çš„å·¥å…·è°ƒç”¨
                                    del tool_calls_buffer[tool_call_index]
                                    
                            except json.JSONDecodeError:
                                print(f"ğŸ” [è°ƒè¯•] JSON å°šæœªå®Œæ•´ï¼Œç»§ç»­ç§¯ç´¯: {current_args}")
                                # ç»§ç»­ç§¯ç´¯ï¼Œç­‰å¾…æ›´å¤šæ•°æ®

                # å¦‚æœæµç»“æŸï¼Œå¤„ç†ä»»ä½•å‰©ä½™çš„å·¥å…·è°ƒç”¨å¹¶å‘é€æœ€ç»ˆäº‹ä»¶
                if is_stop:
                    print(f"ğŸ” [è°ƒè¯•] æµç»“æŸï¼Œæ€»å…±å¤„ç†äº† {chunk_count} ä¸ª chunk")
                    
                    # å¤„ç†ä»»ä½•å‰©ä½™çš„æœªå®Œæˆå·¥å…·è°ƒç”¨
                    for tool_call_index, tool_data in tool_calls_buffer.items():
                        print(f"ğŸ” [è°ƒè¯•] å¤„ç†å‰©ä½™å·¥å…·è°ƒç”¨ index={tool_call_index}: {tool_data}")
                        try:
                            if tool_data['arguments']:
                                args_dict = json.loads(tool_data['arguments'])
                            else:
                                args_dict = {}
                            
                            if tool_data['name']:
                                print(f"ğŸ” [è°ƒè¯•] æ‰§è¡Œå‰©ä½™å·¥å…·è°ƒç”¨: {tool_data['name']}({args_dict})")
                                
                                # å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
                                tool_record = ExecutionRecord(
                                    id=stream_id,
                                    index=chunk_index,
                                    role=Role.ASSISTANT,
                                    tool_call=ToolCall(
                                        name=tool_data['name'],
                                        args=args_dict
                                    ),
                                    is_stop=False
                                )
                                await emit_event(execution_record=tool_record)
                                chunk_index += 1
                                
                                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                                await self._execute_tool_call(
                                    stream_id, chunk_index, tool_data['name'], args_dict
                                )
                                chunk_index += 1
                                
                        except Exception as e:
                            print(f"ğŸ” [è°ƒè¯•] å¤„ç†å‰©ä½™å·¥å…·è°ƒç”¨æ—¶å‡ºé”™: {e}")
                    
                    # æ¸…ç©ºç¼“å†²åŒº
                    tool_calls_buffer.clear()
                    
                    final_record = ExecutionRecord(
                        id=stream_id,
                        index=chunk_index,
                        role=Role.ASSISTANT,
                        reasoning_content=None,
                        content=None,
                        is_stop=True
                    )
                    await emit_event(execution_record=final_record)
                    break
            
            print(f"ğŸ” [è°ƒè¯•] æµå¼å¤„ç†å®Œæˆï¼Œæ€»å…±å¤„ç†äº† {chunk_count} ä¸ª chunk")

        except Exception as e:
            print(f"ğŸ” [è°ƒè¯•] OpenAI API è°ƒç”¨å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            # å‘é€é”™è¯¯äº‹ä»¶
            error_record = ExecutionRecord(
                id=stream_id,
                index=chunk_index,
                role=Role.ASSISTANT,
                content=f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                is_stop=True
            )
            await emit_event(execution_record=error_record)

        # è¿”å›æœ€ç»ˆçš„ç­”æ¡ˆ
        return "æœ€ç»ˆçš„ç­”æ¡ˆ"

    async def _execute_tool_call(self, stream_id: UUID, chunk_index: int, function_name: str, arguments: Dict[str, Any]):
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶å‘é€ç»“æœäº‹ä»¶
        
        Args:
            stream_id: æµID
            chunk_index: å½“å‰å—ç´¢å¼•
            function_name: å‡½æ•°åç§°
            arguments: å‡½æ•°å‚æ•°ï¼ˆå­—å…¸ï¼‰
        """
        try:
            # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°å­—å…¸
            args = arguments
            
            # æ ¹æ®å‡½æ•°åç§°æ‰§è¡Œç›¸åº”çš„å·¥å…·
            if function_name == "get_weather":
                result = get_weather(args.get("city", ""))
                result_text = f"å¤©æ°”æŸ¥è¯¢ç»“æœï¼š{args.get('city')} çš„å¤©æ°”æ˜¯ {result}"
            elif function_name == "get_temperature":
                result = get_temperature(args.get("city", ""))
                result_text = f"æ¸©åº¦æŸ¥è¯¢ç»“æœï¼š{args.get('city')} çš„æ¸©åº¦æ˜¯ {result}Â°C"
            else:
                result_text = f"æœªçŸ¥å·¥å…·ï¼š{function_name}"
            
            # å‘é€å·¥å…·æ‰§è¡Œç»“æœäº‹ä»¶
            result_record = ExecutionRecord(
                id=stream_id,
                index=chunk_index,
                role=Role.TOOL,
                content=result_text,
                is_stop=False
            )
            await emit_event(execution_record=result_record)
            
        except Exception as e:
            # å‘é€é”™è¯¯äº‹ä»¶
            error_record = ExecutionRecord(
                id=stream_id,
                index=chunk_index,
                role=Role.TOOL,
                content=f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}",
                is_stop=False
            )
            await emit_event(execution_record=error_record)
            
async def main():
    agent = ThinkingDemoAgent()
    await agent.run("åŒ—äº¬")

if __name__ == "__main__":
    asyncio.run(main())